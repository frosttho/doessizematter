{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1952d6",
   "metadata": {},
   "source": [
    "_Does size matter? The effect of Instagram influencer account size on post sentiment and resulting marketing outcomes_\n",
    "\n",
    "_Master's thesis by Thomas A. Frost_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5f67c",
   "metadata": {},
   "source": [
    "# Part 3: SiEBERT\n",
    "\n",
    "This file is nearly completely identical with the proposed GitHub template by Siebert et al: https://github.com/chrsiebert/sentiment-roberta-large-english/blob/main/sentiment_roberta_prediction_example.ipynb\n",
    "\n",
    "**ATTENTION! As this file is a Python script, it is not executable on myBinder / GESIS Notebooks in the R environment. To execute the code, download the file and run it locally.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c38f6",
   "metadata": {},
   "source": [
    "## 01 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b85da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
    "\n",
    "from cleantext import remove_emoji, normalize_whitespace\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4742181",
   "metadata": {},
   "source": [
    "## 02 - Create class for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c77aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset:\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbb9ed",
   "metadata": {},
   "source": [
    "## 03 - Import data from Instagram Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809afa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_table(\"../data/Instagram__Posts_corrected_v4.tsv\", sep = \"\\t\")\n",
    "\n",
    "posts.drop(['Date UTC', 'View Count', 'URL of Video', 'URL of Picture-/ Video-Thumbnail', 'Local Filename of Picture / Video Thumbnail', 'Location of Post'], axis = 1, inplace = True)\n",
    "\n",
    "posts.dropna(subset = ['Text'], axis = 0, inplace = True)\n",
    "\n",
    "posts['Text'] = posts['Text'].astype(\"str\")\n",
    "posts['Text'] = posts['Text'].apply(str.replace, args = (\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835074f7",
   "metadata": {},
   "source": [
    "## 04 - remove emojis / convert to ANSII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts['Text'] = posts['Text'].apply(unidecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0f895",
   "metadata": {},
   "source": [
    "## 05 - Load tokenizer and model, create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"siebert/sentiment-roberta-large-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "trainer = Trainer(model=model)\n",
    "\n",
    "pred_texts = posts['Text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fea0c",
   "metadata": {},
   "source": [
    "## 06 - Tokenize texts and create prediction data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)\n",
    "pred_dataset = SimpleDataset(tokenized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9823f1",
   "metadata": {},
   "source": [
    "## 07 - Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddf063",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(pred_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf9bf7",
   "metadata": {},
   "source": [
    "## 08 - Transform predictions to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = pd.Series(preds).map(model.config.id2label)\n",
    "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d26983",
   "metadata": {},
   "source": [
    "## 09 - Create DataFrame with texts, predictions, labels, and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cac412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(pred_texts,preds,labels,scores)), columns=['text','pred','label','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebccb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/predicted-full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
